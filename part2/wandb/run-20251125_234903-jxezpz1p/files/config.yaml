_wandb:
    value:
        cli_version: 0.23.0
        e:
            ikm6a8r17y6m6p2attmqzrb1os6vduna:
                args:
                    - --model-config
                    - model_config.yaml
                    - --train-config
                    - train_config.yaml
                    - --checkpoint-path
                    - checkpoints/part2_Large_layer6_head6_emb192.pt
                codePath: part2/train.py
                codePathLocal: train.py
                cpu_count: 1
                cpu_count_logical: 2
                cudaVersion: "12.4"
                disk:
                    /:
                        total: "120942624768"
                        used: "41377558528"
                email: jemyho1225@gmail.com
                executable: /usr/bin/python3
                git:
                    commit: 876b692ace00f35f71837e0b658cf5916daf3c5c
                    remote: https://JemyHo:@github.com/JemyHo/cw2_2025_2026-students---Jeremy-Lihang.git
                gpu: Tesla T4
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Turing
                      cudaCores: 2560
                      memoryTotal: "16106127360"
                      name: Tesla T4
                      uuid: GPU-fa896f15-fbce-819d-3649-88b668ae137a
                host: df15d68d5de2
                memory:
                    total: "13605851136"
                os: Linux-6.6.105+-x86_64-with-glibc2.35
                program: /content/cw2_2025_2026-students---Jeremy-Lihang/part2/train.py
                python: CPython 3.12.12
                root: /content/cw2_2025_2026-students---Jeremy-Lihang/part2
                startedAt: "2025-11-25T23:49:03.924431Z"
                writerId: ikm6a8r17y6m6p2attmqzrb1os6vduna
        m: []
        python_version: 3.12.12
        t:
            "1":
                - 1
                - 5
                - 53
                - 105
            "2":
                - 1
                - 5
                - 53
                - 105
            "3":
                - 13
                - 16
                - 61
            "4": 3.12.12
            "5": 0.23.0
            "12": 0.23.0
            "13": linux-x86_64
betas:
    value:
        - 0.9
        - 0.95
block_size:
    value: 128
decay_lr:
    value: true
dev_batch_size:
    value: 128
dropout:
    value: 0.1
grad_clip:
    value: 1
log_every:
    value: 10
lr:
    value: 0.0006
max_epoch:
    value: 30
min_lr:
    value: 6e-05
n_embed:
    value: 192
n_head:
    value: 6
n_layer:
    value: 6
patience:
    value: 5
seed:
    value: 0
train_batch_size:
    value: 32
valid_niter:
    value: 2000
vocab_size:
    value: 15003
warmup_percent_iters:
    value: 0.1
weight_decay:
    value: 0.1
